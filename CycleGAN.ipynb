{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work is inspired by paper https://arxiv.org/pdf/1703.10593.pdf, however, we don't attempt to duplicate their exact code and network architecture here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9cbf749990>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from __future__ import print_function\n",
    "# %matplotlib inline\n",
    "# import argparse\n",
    "# import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.nn.parallel\n",
    "# import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "# import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.animation as animation\n",
    "# from IPython.display import HTML\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "class Arguments():\n",
    "    # main parameters\n",
    "\n",
    "    # Root directory for dataset\n",
    "    dataroot = \"data/train\"\n",
    "\n",
    "    # Number of workers for dataloader\n",
    "    workers = 4\n",
    "\n",
    "    # Batch size during training\n",
    "    batch_size = 32\n",
    "\n",
    "    # Spatial size of training images. All images will be resized to this\n",
    "    #   size using a transformer.\n",
    "    image_size = 256\n",
    "\n",
    "    # Number of channels in the group A\n",
    "    input_nc = 3\n",
    "    \n",
    "    # Number of channels in the group B\n",
    "    output_nc = 3\n",
    "\n",
    "    # number of filters in the last conv layer of generator\n",
    "    ngf = 8\n",
    "\n",
    "    # number of filters in the first conv layer of discriminator\n",
    "    ndf = 8\n",
    "\n",
    "    # Number of training epochs\n",
    "    num_epochs = 5\n",
    "\n",
    "    # Learning rate for optimizers\n",
    "    lr = 0.0002\n",
    "    \n",
    "    # identity_loss coeff.\n",
    "    lambda_identity = 0.1\n",
    "\n",
    "    # Beta1 hyperparam for Adam optimizers\n",
    "    beta1 = 0.5\n",
    "\n",
    "    # Number of GPUs available. Use 0 for CPU mode.\n",
    "    ngpu = 1\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "    print(device)\n",
    "    \n",
    "opt = Arguments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need two generators and two discriminators, here we define them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            input_nc (int) -- the number of channels in input images\n",
    "            output_nc (int) -- the number of channels in output images\n",
    "            ngf (int) -- the number of filters in the last conv layer\n",
    "        Returns a generator\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__(input_nc, output_nc, ngf)\n",
    "        self.main = nn.Sequential(\n",
    "            # Down sampling\n",
    "            nn.Conv2d(input_nc, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size.  ngf x (image_size/2) x (image_size/2)\n",
    "            \n",
    "            nn.Conv2d(ngf, ngf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ngf*2 x (image_size/4) x (image_size/4)\n",
    "            \n",
    "            nn.Conv2d(ngf*2, ngf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ngf*4 x (image_size/8) x (image_size/8)\n",
    "            \n",
    "            # ---\n",
    "            # Up sampling\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ngf*2 x (image_size/4) x (image_size/4)\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x image_size/2 x image_size/2\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf, output_nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (output_nc) x image_size x image_size\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator Code    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            input_nc (int)  -- the number of channels in input images\n",
    "            ndf (int)       -- the number of filters in the last conv layer\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__(input_nc, ndf)\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (input_nc) x image_size x image_size\n",
    "            nn.Conv2d(input_nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x image_size/2 x image_size/2\n",
    "            \n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x image_size/4 x image_size/4\n",
    "            \n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x image_size/8 x image_size/8\n",
    "            \n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x image_size/16 x image_size/16\n",
    "            \n",
    "            nn.Conv2d(ndf * 8, ndf * 16, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*16) x image_size/32 x image_size/32\n",
    "            \n",
    "            nn.Conv2d(ndf * 16, ndf * 32, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*32) x image_size/64 x image_size/64\n",
    "            \n",
    "            nn.Conv2d(ndf * 32, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGANModel():\n",
    "    def __init__(self, opt):\n",
    "        # specify the training losses you want to print out.\n",
    "        self.loss_names = ['D_A', 'G_A', 'cycle_A', 'idt_A', 'D_B', 'G_B', 'cycle_B', 'idt_B']\n",
    "        \n",
    "        # specify the images you want to save/display.\n",
    "        visual_names_A = ['real_A', 'fake_B', 'rec_A', 'idt_B']\n",
    "        visual_names_B = ['real_B', 'fake_A', 'rec_B', 'idt_A']\n",
    "        \n",
    "        self.visual_names = visual_names_A + visual_names_B  # combine visualizations for A and B\n",
    "        \n",
    "        self.model_names = ['G_A', 'G_B', 'D_A', 'D_B']\n",
    "        \n",
    "        # define networks (both Generators and discriminators)\n",
    "        self.netG_A = Generator(opt.input_nc, opt.output_nc, opt.ngf)\n",
    "        self.netG_B = Generator(opt.output_nc, opt.input_nc, opt.ngf)\n",
    "        \n",
    "        self.netD_A = Discriminator(opt.output_nc, opt.ndf)\n",
    "        self.netD_B = Discriminator(opt.input_nc, opt.ndf)\n",
    "        \n",
    "#         self.fake_A_pool = ImagePool(opt.pool_size)  # create image buffer to store previously generated images\n",
    "#         self.fake_B_pool = ImagePool(opt.pool_size)  # create image buffer to store previously generated images\n",
    "            \n",
    "        # define loss functions\n",
    "#         self.criterionGAN = ? # define GAN loss.\n",
    "        self.criterionCycle = torch.nn.L1Loss()\n",
    "        self.criterionIdt = torch.nn.L1Loss()\n",
    "        \n",
    "        # initialize optimizers; schedulers will be automatically created by function <BaseModel.setup>.\n",
    "        self.optimizer_G = torch.optim.Adam(itertools.chain(self.netG_A.parameters(), self.netG_B.parameters()), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "        self.optimizer_D = torch.optim.Adam(itertools.chain(self.netD_A.parameters(), self.netD_B.parameters()), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "        self.optimizers.append(self.optimizer_G)\n",
    "        self.optimizers.append(self.optimizer_D)\n",
    "        \n",
    "    def set_input(self, input):\n",
    "        \"\"\"Unpack input data from the dataloader\"\"\"\n",
    "        self.real_A = input['A']\n",
    "        self.real_B = input['B']\n",
    "        \n",
    "    def forward(self):\n",
    "        \"\"\"Run forward pass\"\"\"\n",
    "        self.fake_B = self.netG_A(self.real_A)  # G_A(A)\n",
    "        self.rec_A = self.netG_B(self.fake_B)   # G_B(G_A(A))\n",
    "        self.fake_A = self.netG_B(self.real_B)  # G_B(B)\n",
    "        self.rec_B = self.netG_A(self.fake_A)   # G_A(G_B(B))\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
