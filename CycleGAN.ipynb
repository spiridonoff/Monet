{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work is inspired by paper https://arxiv.org/pdf/1703.10593.pdf, however, we don't attempt to duplicate their exact code and network architecture here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f05d26c3cf0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "# import matplotlib.animation as animation\n",
    "# from IPython.display import HTML\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "class Arguments():\n",
    "    # main parameters\n",
    "\n",
    "    # Root directory for dataset\n",
    "    dataroot_A = \"data/train_photo\"\n",
    "    dataroot_B = \"data/train_monet\"\n",
    "\n",
    "    # Number of workers for dataloader\n",
    "    workers = 4\n",
    "\n",
    "    # Batch size during training\n",
    "    batch_size = 16\n",
    "\n",
    "    # Spatial size of training images. All images will be resized to this\n",
    "    #   size using a transformer.\n",
    "    image_size = 256\n",
    "\n",
    "    # Number of channels in the group A\n",
    "    input_nc = 3\n",
    "    \n",
    "    # Number of channels in the group B\n",
    "    output_nc = 3\n",
    "\n",
    "    # number of filters in the last conv layer of generator\n",
    "    ngf = 8\n",
    "\n",
    "    # number of filters in the first conv layer of discriminator\n",
    "    ndf = 8\n",
    "\n",
    "    # Number of training epochs\n",
    "    n_epochs = 5\n",
    "\n",
    "    # Learning rate for optimizers\n",
    "    lr = 0.0002\n",
    "    \n",
    "    # identity_loss coeff.\n",
    "    lambda_identity = 0.1\n",
    "    lambda_A = 0.5\n",
    "    lambda_B = 0.5\n",
    "\n",
    "    # Beta1 hyperparam for Adam optimizers\n",
    "    beta1 = 0.5\n",
    "\n",
    "    # Number of GPUs available. Use 0 for CPU mode.\n",
    "    ngpu = 1\n",
    "    \n",
    "    gan_mode = 'lsgan' # 'vanilla', 'wgangp'\n",
    "    \n",
    "    pool_size = 4\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "    print(device)\n",
    "    \n",
    "opt = Arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset to return pairs of images from both 2 styles\n",
    "class UnpairedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, opt):\n",
    "        self.path_A = opt.dataroot_A\n",
    "        self.path_B = opt.dataroot_B\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(opt.image_size),\n",
    "            transforms.CenterCrop(opt.image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "        \n",
    "        self.datasetA = dset.ImageFolder(root = self.path_A, transform = transform)\n",
    "        self.datasetB = dset.ImageFolder(root = self.path_B, transform = transform)\n",
    "        \n",
    "        self.size_A = len(self.datasetA)\n",
    "        self.size_B = len(self.datasetB)\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(self.size_A, self.size_B)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        A_tensor = self.datasetA[index % self.size_A][0]\n",
    "        \n",
    "        index_B = random.randint(0, self.size_B - 1)\n",
    "        B_tensor = self.datasetB[index_B][0]\n",
    "        \n",
    "        return {'A': A_tensor, 'B': B_tensor}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need two generators and two discriminators, here we define them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, ngf):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            input_nc (int) -- the number of channels in input images\n",
    "            output_nc (int) -- the number of channels in output images\n",
    "            ngf (int) -- the number of filters in the last conv layer\n",
    "        Returns a generator\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # Down sampling\n",
    "            nn.Conv2d(input_nc, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size.  ngf x (image_size/2) x (image_size/2)\n",
    "            \n",
    "            nn.Conv2d(ngf, ngf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ngf*2 x (image_size/4) x (image_size/4)\n",
    "            \n",
    "            nn.Conv2d(ngf*2, ngf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ngf*4 x (image_size/8) x (image_size/8)\n",
    "            \n",
    "            # ---\n",
    "            # Up sampling\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ngf*2 x (image_size/4) x (image_size/4)\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x image_size/2 x image_size/2\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf, output_nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (output_nc) x image_size x image_size\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator Code    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc, ndf):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            input_nc (int)  -- the number of channels in input images\n",
    "            ndf (int)       -- the number of filters in the last conv layer\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (input_nc) x image_size x image_size\n",
    "            nn.Conv2d(input_nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x image_size/2 x image_size/2\n",
    "            \n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x image_size/4 x image_size/4\n",
    "            \n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x image_size/8 x image_size/8\n",
    "            \n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x image_size/16 x image_size/16\n",
    "            \n",
    "            nn.Conv2d(ndf * 8, ndf * 16, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*16) x image_size/32 x image_size/32\n",
    "            \n",
    "            nn.Conv2d(ndf * 16, ndf * 32, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*32) x image_size/64 x image_size/64\n",
    "            \n",
    "            nn.Conv2d(ndf * 32, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "    \"\"\"Define different GAN objectives.\n",
    "\n",
    "    The GANLoss class abstracts away the need to create the target label tensor\n",
    "    that has the same size as the input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gan_mode, target_real_label=1.0, target_fake_label=0.0):\n",
    "        \"\"\" Initialize the GANLoss class.\n",
    "\n",
    "        Parameters:\n",
    "            gan_mode (str) - - the type of GAN objective. It currently supports vanilla, lsgan, and wgangp.\n",
    "            target_real_label (bool) - - label for a real image\n",
    "            target_fake_label (bool) - - label of a fake image\n",
    "\n",
    "        Note: Do not use sigmoid as the last layer of Discriminator.\n",
    "        LSGAN needs no sigmoid. vanilla GANs will handle it with BCEWithLogitsLoss.\n",
    "        \"\"\"\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
    "        self.gan_mode = gan_mode\n",
    "        if gan_mode == 'lsgan':\n",
    "            self.loss = nn.MSELoss()\n",
    "        elif gan_mode == 'vanilla':\n",
    "            self.loss = nn.BCEWithLogitsLoss()\n",
    "        elif gan_mode in ['wgangp']:\n",
    "            self.loss = None\n",
    "        else:\n",
    "            raise NotImplementedError('gan mode %s not implemented' % gan_mode)\n",
    "\n",
    "    def get_target_tensor(self, prediction, target_is_real):\n",
    "        \"\"\"Create label tensors with the same size as the input.\n",
    "\n",
    "        Parameters:\n",
    "            prediction (tensor) - - tpyically the prediction from a discriminator\n",
    "            target_is_real (bool) - - if the ground truth label is for real images or fake images\n",
    "\n",
    "        Returns:\n",
    "            A label tensor filled with ground truth label, and with the size of the input\n",
    "        \"\"\"\n",
    "\n",
    "        if target_is_real:\n",
    "            target_tensor = self.real_label\n",
    "        else:\n",
    "            target_tensor = self.fake_label\n",
    "        return target_tensor.expand_as(prediction)\n",
    "\n",
    "    def __call__(self, prediction, target_is_real):\n",
    "        \"\"\"Calculate loss given Discriminator's output and ground truth labels.\n",
    "\n",
    "        Parameters:\n",
    "            prediction (tensor) - - tpyically the prediction output from a discriminator\n",
    "            target_is_real (bool) - - if the ground truth label is for real images or fake images\n",
    "\n",
    "        Returns:\n",
    "            the calculated loss.\n",
    "        \"\"\"\n",
    "        if self.gan_mode in ['lsgan', 'vanilla']:\n",
    "            target_tensor = self.get_target_tensor(prediction, target_is_real)\n",
    "            loss = self.loss(prediction, target_tensor)\n",
    "        elif self.gan_mode == 'wgangp':\n",
    "            if target_is_real:\n",
    "                loss = -prediction.mean()\n",
    "            else:\n",
    "                loss = prediction.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePool():\n",
    "    \"\"\"This class implements an image buffer that stores previously generated images.\n",
    "\n",
    "    This buffer enables us to update discriminators using a history of generated images\n",
    "    rather than the ones produced by the latest generators.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pool_size):\n",
    "        \"\"\"Initialize the ImagePool class\n",
    "\n",
    "        Parameters:\n",
    "            pool_size (int) -- the size of image buffer, if pool_size=0, no buffer will be created\n",
    "        \"\"\"\n",
    "        self.pool_size = pool_size\n",
    "        if self.pool_size > 0:  # create an empty pool\n",
    "            self.num_imgs = 0\n",
    "            self.images = []\n",
    "\n",
    "    def query(self, images):\n",
    "        \"\"\"Return an image from the pool.\n",
    "\n",
    "        Parameters:\n",
    "            images: the latest generated images from the generator\n",
    "\n",
    "        Returns images from the buffer.\n",
    "\n",
    "        By 50/100, the buffer will return input images.\n",
    "        By 50/100, the buffer will return images previously stored in the buffer,\n",
    "        and insert the current images to the buffer.\n",
    "        \"\"\"\n",
    "        if self.pool_size == 0:  # if the buffer size is 0, do nothing\n",
    "            return images\n",
    "        return_images = []\n",
    "        for image in images:\n",
    "            image = torch.unsqueeze(image.data, 0)\n",
    "            if self.num_imgs < self.pool_size:   # if the buffer is not full; keep inserting current images to the buffer\n",
    "                self.num_imgs = self.num_imgs + 1\n",
    "                self.images.append(image)\n",
    "                return_images.append(image)\n",
    "            else:\n",
    "                p = random.uniform(0, 1)\n",
    "                if p > 0.5:  # by 50% chance, the buffer will return a previously stored image, and insert the current image into the buffer\n",
    "                    random_id = random.randint(0, self.pool_size - 1)  # randint is inclusive\n",
    "                    tmp = self.images[random_id].clone()\n",
    "                    self.images[random_id] = image\n",
    "                    return_images.append(tmp)\n",
    "                else:       # by another 50% chance, the buffer will return the current image\n",
    "                    return_images.append(image)\n",
    "        return_images = torch.cat(return_images, 0)   # collect all the images and return\n",
    "        return return_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGANModel():\n",
    "    def __init__(self, opt):\n",
    "        # specify the training losses you want to print out.\n",
    "        \n",
    "        self.opt = opt\n",
    "        self.loss_names = ['D_A', 'G_A', 'cycle_A', 'idt_A', 'D_B', 'G_B', 'cycle_B', 'idt_B']\n",
    "        \n",
    "        # specify the images you want to save/display.\n",
    "        visual_names_A = ['real_A', 'fake_B', 'rec_A', 'idt_B']\n",
    "        visual_names_B = ['real_B', 'fake_A', 'rec_B', 'idt_A']\n",
    "        \n",
    "        self.visual_names = visual_names_A + visual_names_B  # combine visualizations for A and B\n",
    "        \n",
    "        self.model_names = ['G_A', 'G_B', 'D_A', 'D_B']\n",
    "        \n",
    "        # define networks (both Generators and discriminators)\n",
    "        self.netG_A = Generator(opt.input_nc, opt.output_nc, opt.ngf).to(opt.device)\n",
    "        self.netG_B = Generator(opt.output_nc, opt.input_nc, opt.ngf).to(opt.device)\n",
    "        \n",
    "        self.netD_A = Discriminator(opt.output_nc, opt.ndf).to(opt.device)\n",
    "        self.netD_B = Discriminator(opt.input_nc, opt.ndf).to(opt.device)\n",
    "        \n",
    "        self.fake_A_pool = ImagePool(opt.pool_size)  # create image buffer to store previously generated images\n",
    "        self.fake_B_pool = ImagePool(opt.pool_size)  # create image buffer to store previously generated images\n",
    "            \n",
    "        # define loss functions\n",
    "        self.criterionGAN = GANLoss(opt.gan_mode).to(opt.device)\n",
    "        self.criterionCycle = torch.nn.L1Loss()\n",
    "        self.criterionIdt = torch.nn.L1Loss()\n",
    "        \n",
    "        # initialize optimizers; schedulers will be automatically created by function <BaseModel.setup>.\n",
    "        self.optimizers = []\n",
    "        self.optimizer_G = torch.optim.Adam(itertools.chain(self.netG_A.parameters(), self.netG_B.parameters()), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "        self.optimizer_D = torch.optim.Adam(itertools.chain(self.netD_A.parameters(), self.netD_B.parameters()), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "        self.optimizers.append(self.optimizer_G)\n",
    "        self.optimizers.append(self.optimizer_D)\n",
    "        \n",
    "    def set_requires_grad(self, nets, requires_grad=False):\n",
    "        \"\"\"Set requies_grad=Fasle for all the networks to avoid unnecessary computations\n",
    "        Parameters:\n",
    "            nets (network list)   -- a list of networks\n",
    "            requires_grad (bool)  -- whether the networks require gradients or not\n",
    "        \"\"\"\n",
    "        if not isinstance(nets, list):\n",
    "            nets = [nets]\n",
    "        for net in nets:\n",
    "            if net is not None:\n",
    "                for param in net.parameters():\n",
    "                    param.requires_grad = requires_grad\n",
    "                    \n",
    "    def set_input(self, input):\n",
    "        \"\"\"Unpack input data from the dataloader\"\"\"\n",
    "        self.real_A = input['A']\n",
    "        self.real_B = input['B']\n",
    "        \n",
    "    def forward(self):\n",
    "        \"\"\"Run forward pass\"\"\"\n",
    "        self.fake_B = self.netG_A(self.real_A)  # G_A(A)\n",
    "        self.rec_A = self.netG_B(self.fake_B)   # G_B(G_A(A))\n",
    "        self.fake_A = self.netG_B(self.real_B)  # G_B(B)\n",
    "        self.rec_B = self.netG_A(self.fake_A)   # G_A(G_B(B))\n",
    "        \n",
    "    def backward_D_basic(self, netD, real, fake):\n",
    "        \"\"\"Calculate GAN loss for the discriminator\n",
    "\n",
    "        Parameters:\n",
    "            netD (network)      -- the discriminator D\n",
    "            real (tensor array) -- real images\n",
    "            fake (tensor array) -- images generated by a generator\n",
    "\n",
    "        Return the discriminator loss.\n",
    "        We also call loss_D.backward() to calculate the gradients.\n",
    "        \"\"\"\n",
    "        # Real\n",
    "        pred_real = netD(real)\n",
    "        loss_D_real = self.criterionGAN(pred_real, True)\n",
    "        # Fake\n",
    "        pred_fake = netD(fake.detach())\n",
    "        loss_D_fake = self.criterionGAN(pred_fake, False)\n",
    "        # Combined loss and calculate gradients\n",
    "        loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "        loss_D.backward()\n",
    "        return loss_D\n",
    "    \n",
    "    def backward_D_A(self):\n",
    "        \"\"\"Calculate GAN loss for discriminator D_A\"\"\"\n",
    "        fake_B = self.fake_B_pool.query(self.fake_B)\n",
    "        self.loss_D_A = self.backward_D_basic(self.netD_A, self.real_B, fake_B)\n",
    "        \n",
    "    def backward_D_B(self):\n",
    "        \"\"\"Calculate GAN loss for discriminator D_B\"\"\"\n",
    "        fake_A = self.fake_A_pool.query(self.fake_A)\n",
    "        self.loss_D_B = self.backward_D_basic(self.netD_B, self.real_A, fake_A)\n",
    "        \n",
    "    def backward_G(self):\n",
    "        \"\"\"Calculate the loss for generators G_A and G_B\"\"\"\n",
    "        lambda_idt = self.opt.lambda_identity\n",
    "        lambda_A = self.opt.lambda_A\n",
    "        lambda_B = self.opt.lambda_B\n",
    "        # Identity loss\n",
    "        if lambda_idt > 0:\n",
    "            # G_A should be identity if real_B is fed: ||G_A(B) - B||\n",
    "            self.idt_A = self.netG_A(self.real_B)\n",
    "            self.loss_idt_A = self.criterionIdt(self.idt_A, self.real_B) * lambda_B * lambda_idt\n",
    "            # G_B should be identity if real_A is fed: ||G_B(A) - A||\n",
    "            self.idt_B = self.netG_B(self.real_A)\n",
    "            self.loss_idt_B = self.criterionIdt(self.idt_B, self.real_A) * lambda_A * lambda_idt\n",
    "        else:\n",
    "            self.loss_idt_A = 0\n",
    "            self.loss_idt_B = 0\n",
    "\n",
    "        # GAN loss D_A(G_A(A))\n",
    "        self.loss_G_A = self.criterionGAN(self.netD_A(self.fake_B), True)\n",
    "        # GAN loss D_B(G_B(B))\n",
    "        self.loss_G_B = self.criterionGAN(self.netD_B(self.fake_A), True)\n",
    "        # Forward cycle loss || G_B(G_A(A)) - A||\n",
    "        self.loss_cycle_A = self.criterionCycle(self.rec_A, self.real_A) * lambda_A\n",
    "        # Backward cycle loss || G_A(G_B(B)) - B||\n",
    "        self.loss_cycle_B = self.criterionCycle(self.rec_B, self.real_B) * lambda_B\n",
    "        # combined loss and calculate gradients\n",
    "        self.loss_G = self.loss_G_A + self.loss_G_B + self.loss_cycle_A + self.loss_cycle_B + self.loss_idt_A + self.loss_idt_B\n",
    "        self.loss_G.backward()\n",
    "        \n",
    "    def optimize_parameters(self):\n",
    "        \"\"\"Calculate losses, gradients, and update network weights; called in every training iteration\"\"\"\n",
    "        # forward\n",
    "        self.forward()      # compute fake images and reconstruction images.\n",
    "        # G_A and G_B\n",
    "        self.set_requires_grad([self.netD_A, self.netD_B], False)  # Ds require no gradients when optimizing Gs\n",
    "        self.optimizer_G.zero_grad()  # set G_A and G_B's gradients to zero\n",
    "        self.backward_G()             # calculate gradients for G_A and G_B\n",
    "        self.optimizer_G.step()       # update G_A and G_B's weights\n",
    "        # D_A and D_B\n",
    "        self.set_requires_grad([self.netD_A, self.netD_B], True)\n",
    "        self.optimizer_D.zero_grad()   # set D_A and D_B's gradients to zero\n",
    "        self.backward_D_A()      # calculate gradients for D_A\n",
    "        self.backward_D_B()      # calculate graidents for D_B\n",
    "        self.optimizer_D.step()  # update D_A and D_B's weights\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6ca080940411>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# TODO: define dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mdata_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_device\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# unpack data from dataset and apply preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# calculate loss functions, get gradients, update network weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "## main loop\n",
    "\n",
    "model = CycleGANModel(opt)\n",
    "    \n",
    "unpaired_dataset = UnpairedDataset(opt)\n",
    "dataloader = torch.utils.data.DataLoader(unpaired_dataset, batch_size=opt.batch_size, shuffle=True, num_workers=opt.workers)\n",
    "    \n",
    "for epoch in range(opt.n_epochs):\n",
    "    # TODO: define dataset    \n",
    "    for i, data in enumerate(dataloader):\n",
    "        data_device = data.to(opt.device)\n",
    "        model.set_input(data_device)         # unpack data from dataset and apply preprocessing\n",
    "        model.optimize_parameters()   # calculate loss functions, get gradients, update network weights\n",
    "    if i % 100 == 0:\n",
    "        # print losses at the end of each epoch\n",
    "        print(f\"{epoch}: {model.loss_G}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
